# `파드와 클러스터 노드의 오토스케일링`

## 목차

<br>

---
---

<br>

## 서론

스케일을 수동으로 제어하는 건 순간적인 부하를 예측할 수 있거나, 부하가 장시간에 걸쳐 점진적으로 변화하는 경우에는 고내찮다.

하지만 갑자기 발생하는 예측할 수 없는 트래픽 증가 현상을 수동으로 개입해 처리하는 것은 이상적이지 않다.

쿠버네티스는 이런 상황에 대해 오토 스케일링 기능을 제공한다.

<br>

---
---

<br>

## 수평적 파드 오토스케일링

Horizontal 컨트롤러에 의해 관리 파드의 레플리카 수를 자동으로 조정하는 것으로,

HorizontalPodAutoscaler(HPA) 리소스를 작성해 활성화시키고 원하는 대로 설정한다.

컨트롤러는 주기적으로 파드 메트릭을 확인해, HPA 리소스에 설정됑 있는 대상 메트릭 값을 만족하는 레플리카 수를 계산한다.

그리고 대상 리소스(디플러이먼트, 레플리카셋, 레플리케이션컨트롤러, 스테이트풀셋) 안에 있는 replicas 필드 값을 조정한다.

---

<br>

### 오토스케일링 프로세스 이해

- 확장 가능한 리소스 오브젝트에서 관리하는 모든 파드의 메트릭을 가져온다.
- 메트릭을 지정한 목표 값과 같거나 가깝도록 하기 위해 필요한 파드 수를 계산한다.
- 확장 가능한 리소스의 replicas 필드를 갱신한다.

<br>

***파드 메트릭 얻기***

파드와 노드메트릭은 모든 노드에서 실행되는 kubelet에서 실행되는 cAdvisor 에이전트에 의해 수집된다.

수집한 메트릭은 클러스터 전역 구성 요소인 메트릭서버에 의해 집계된다.

HPA는 REST를 통해 메트릭 서버에 질의해 모든 파드의 메트릭을 가져온다.

<br>

***필요한 파드 수 계산***

모든 레플리카에서 메트릭의 평균 값을 이용해 지정한 목표 값과 가능한 가깝게 하는 숫자를 찾아야 한다.

오토스케일러가 단일 메트릭만을 고려하도록 설정돼 있다면, 모든 메트릭 값을 더한 뒤 HPA 리소스에 정의된 목표 값으로 나눈 값을 그 다음으로 큰 정수로 반올림해서 구한다.

실제 계산은 메트릭 값이 불안정한 상태에서 빠르게 변할 때 오토스케일러가 같이 요동치지 않도록 하기 때문에 더 복잡하다.

만약 여러 파드 메트릭을 기반으로 하는 경우는 각 메트릭의 레플리카 수를 개별적으로 계산한 뒤 가장 높은 값을 취한다.

(게산했을 때 A 메트릭 관련하여 4개가 필요하고 B 메트릭 관련하여 3개가 필요하다면 4개로 확장한다는 이야기)

<br>

***스케일링된 리소스의 레플리카 수 갱신***

오토스케일링 작업의 마지막 단계는 스케일링된 리소스 오브젝트의 레플리카 개수 필드를 원하는 값으로 갱신해,

레플리카셋 컨트롤러가 추가 파드를 시작하거나 초과한 파드를 삭제하도록 하는 것이다.

오토스케일러 컨트롤러는 스케일 대상 리소스의 replicas 필드를 스케일 서브 리소스(scale sub-resource)를 통해 변경한다.

오토스케일러를 붙일 수 있는 오브젝트는 다음과 같다.

- 디플로이먼트
- 레플리카셋
- 레플리케이션컨트롤러
- 스테이트풀셋

<br>

***전체 오토스케일링 과정 이해***

<img src="https://user-images.githubusercontent.com/37579681/127740318-62e2834a-9000-4bb4-871e-998bd9b616ac.jpeg">

중요한 점은 각 구성 요소는 메트릭을 다른 구성 요소에서 주기적으로 가져오기 때문에 **즉각적으로 재조정이 이루어지지 않는다는 점**이다.

<br>

---

<br>

### CPU 사용률 기반 스케일링

CPU 사용량이 100%에 도달하게 되면 스케일 업이나 스케일 아웃이 필요하다.

CPU가 완전히 바쁜 상태에 도달하기 전에 스케일 아웃을 수행하는 것이 좋다.

그런데 어떻게 정확히 80%라는 것을 알 수 있을까?

오토스케일러에 한해서는 파드의 CPU 사용률을 결정할 때 파드가 보장받은 CPU 사용량만이 중요하다.

오토스케일러는 파드의 실제 CPU 사용량과 CPU 요청을 비교하는데, 

이는 오토스케일링이 필요한 파드는 오토스케일러가 CPU 사용률을 결정하기 위해서

오토스케일링이 필요한 파드는 오토스케일러가 CPU 사용률을 결정하기 위해서 

오토스케일링이 필요한 파드는 직접 또는 간접적으로 LimitRange 오브젝트를 통해 CPU 요청을 설정해야 한다는 것이다.

<br>

***CPU 사용량을 기반으로 HPA 생성***

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  replicas: 3
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v1
        name: nodejs
        resources:
          requests:
            cpu: 100m
```

일반적인 디플로이먼트 오브젝트로, 아직 오토스케일링을 사용하지 않았다.

세 개의 kubia NodeJS 애플리케이션 인스턴스를 실행하면서, 각 인스턴스는 100밀리코어의 CPU 사용량을 요청한다.

HPA를 생성해보자.

```bash
# CPU 사용률을 30%대로 유지하기 위해 레플리카 수를 조정하지만
# 1개 미만으로 줄이거나 5개를 초과하는 레플리카를 만들지는 않는다.
$ kubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5

# HPA 리소스 정의를 보자
$ kubectl get hpa.v2beta1.autoscaling kubia -o yaml
```

***항상 레플리카 셋이 아닌 디플로이먼트를 오토스케일 대상으로 해야 한다. 이렇게 하면 애플리케이션 업데이트 시에도 원하는 레플리카 수를 계속 유지할 수 있다.***

<br>

***최초 오토 리스케일 이벤트 보기***

3개의 파드가 있는 상황에서 오토스케일러가 디플로이먼트 크기를 조정해 하나의 레플리카만 남긴다. 

<br>

***스케일 업 일으키기***

먼저 생성된 모든 파드를 서비스를 통해 노출하자.

```bash
# 서비스로 노출
$ kubectl expose deployment kubia --port=80 --target-port=8080

# HPA와 Deployment에 무슨 일이 벌어지는지 보자
$ watch -n 1 kubectl get hpa,deployment

# 다른 터미널에서 다음 명령어를 실행해서 서비스에 반복적으로 접속하는 파드를 실행하자.
# 부하를 생성하는 파드다.
$ kubectl run -it --rm --restart=Never loadgenerator --image=busybox --sh -c "while true; do wget -O - -q http://kubia.default; done"
```

부하를 생성하는 파드가 있기 때문에 메트릭 갱신 이후 30%에 가깝고 관찰된 CPU 사용률과 비슷하게 유지되는 수로 파드가 증가하게 된다.

<br>

***최대 스케일링 비율 이해***

한 번의 확장 단계에서 추가할 수 있는 레플리카 수는 제한돼 있기 때문에 

오토스케일러는 두 개를 초과하는 레플리카가 존재할 경우 한 번의 수행에서 최대 두 배의 레플리카를 생성할 수 있다.

만약 한 개 또는 두 개의 레플리카가 존재하면 한 단계에서 최대 네 개의 레플리카까지 확장될 수 있다.

또한 이전 작업 이후에 이어지는 오토스케일 작업이 얼마나 빨리 일어날 수 있는지에 대한 제한도 있다.

지난 3분 동안 아무런 리스케일링 이벤트가 발생하지 않을 경우에만 스케일 업이 일어난다.

스케일 다운 이벤트는 5분 간격으로 조금 더 적게 일어난다.

<br>

***기존 HPA 오브젝트에서 목표 메트릭 값 변경***

kubectl edit 명령으로 HPA 리소스를 편집해서 targetAverageUtilization 필드 값을 60으로 변경하여 적용할 수 있다.

<br>

---

<br>

### 메모리 소비량에 기반을 둔 스케일링

메모리 기반 오토스케일링은 CPU 기반 오토스케일링에 비해 훨씬 문제가 많다.

가장 큰 이유는 스케일 업 후에 오래된 파드는 어떻게든 메모리를 해제하는 것이 필요하기 때문이다.

해제하는 작업은 애플리케이션이 직접 해야하며 시스템이 할 수 있는 것이 아니다.

시스템이 할 수 있는 것은 이전보다 적은 메모리를 사용하기를 기대하면서 애플리케이션을 종료하고 다시 시작하는 것 뿐이다.

그러나 애플리케이션이 이전과 같은 메모리를 사용하면 오토스케일러는 다시 스케일 업을 한다.

이 반복 작업은 HPA 리소스에 설정된 최대 파드 수에 도달할 때까지 계속 진행한다.

메모리 기반 오토스케일링은 CPU 기반 오토스케일링과 똑같이 설정할 수 있다.

<br>

---

<br>

### 기타 그리고 사용자 정의 메트릭 기반 스케일링

초기에는 오직 CPU 사용량을 기반으로 파드를 확장할 수 있었지만, 지금은 다양한 사용자 정의 메트릭 기반으로 오토스케일링을 할 수 있따.

HPA 오브젝트에는 사용할 수 있는 세 가지 유형의 메트릭이 있다.

- 리소스
- 파드
- 오브젝트

<br>

***리소스 메트릭***

리소스 유형은 우리가 여태까지 다 본 것이다.

<br>

***파드 메트릭***

Pods 유형은 다른 여러 메트릭을 직접 참조하는 데 사용된다.

초당 질의 수(QPS) 또는 메시지 브로커의 큐 메시지 수 등이 있다.

HPA 오브젝트에 이런 식으로 설정할 수 있다.

```yaml
...
spec:
  metrics:
  - type: Pods
    resources:
      # 메트릭 이름
      metricName: qps
      # 모든 대상 파드의 목표 평균 값
      targetAverageValue: 100
```

<br>

***오브젝트 메트릭***

Object 메트릭 유형은 오토스케일러가 파드를 확장할 때 파드에 직접 관련되지 않는 메트릭을 기반으로 하도록 만든다.

예를 들어 파드를 확장할 때 인그레스 오브젝트 같은 클러스터 오브젝트 메트릭을 이용할 수 있다.

오토스케일러가 모든 대상 파드 메트릭을 얻어 평균 값을 사용하는 이전 경우와 달리, Object 데이터 유형을 사용해 하나의 오브젝트에서 단일 메트릭을 얻을 수 있다.

```yaml
...
spec:
  metrics:
  - type: Object
    resource:
      metricName: latencyMillis
      target:
        apiVersion: extensions/v1beta1
        kind: Ingress
        name: frontend
      targetValue: 20
      scaleTargetRef:
        apiVersion: extensions/v1beta1
        kind: Deployment
        name: kubia
```

이 예제에서 HPA는 frontend 인그레스 오브젝트의 latencyMillis 메트릭을 사용하도록 되어 있다.

수평적 파드 오토스케일러는 해당 메트릭을 모니터링하고 목표 값보다 높이 올라갈 경우 오토스케일러가 kubia 디플로이먼트 리소스를 확장한다.

<br>

---

<br>

### 오토스케일링에 적합한 메트릭 결정

오토스케일러 애플리케이션 정의 메트릭을 오토스케일러의 기반 항목으로 하기 전에, 파드 수가 증가하고 감소할 때 메트릭 값이 어떻게 변화하는지 고려해야 한다.

<br>

---

<br>

### 레플리카를 0으로?

수평적 파드 오토스케일러는 현재 minReplicas를 0으로 설정할 수 없기 때문에

파드가 아무것도 하지 않더라도 오토스케일러는 파드 수를 0으로 감소시키지 않는다.

이런 유휴 해제의 경우 하드웨어 사용률을 크게 높일 수 있기 때문에 나중에 추가될 수도 있다.

찾아보니 가능한 거 같기는 하다.

<br>

---

<br>

## 수직적 파드 오토스케일링

파드의 리소스 요청은 파드 매니페스트 안에 있는 필드로 설정하기 때문에 수직적 파드 확장은 이 필드를 변경해 수행할 수 있다.

참고로 VerticalPodAutoscaler라는 객체가 있다.

https://cloud.google.com/kubernetes-engine/docs/how-to/vertical-pod-autoscaling?hl=ko

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: my-rec-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind:       Deployment
    name:       my-rec-deployment
  updatePolicy:
    updateMode: "Off"
```

<br>

---
---

<br>

## 수평적 클러스터 노드 확장

수평적 파드 오토스케일러는 필요할 때 추가 파드 인스턴스를 생성한다.

그러나 모든 노드가 한계에 도달해 더 이상 파드를 추가할 수 없다면?

이 경우에는 기존 파드 중 몇 개를 삭제하거나 파드가 사용하는 자원을 줄이거나 아니면 새로운 노드를 추가해야 한다.

클러스터를 클라우드 인프라스트럭처에서 운영하고 있을 때 새로운 노드를 추가하는 것은 몇 번이나 클릭이나 API 호출로 할 수 있다.

또한 이 작업을 클러스터 오토스케일러를 이용하여 자동으로 수행할 수도 있다.

<br>

---

<br>

### 클러스터 오토스케일러 소개

클러스터 오토스케일러는 노드에 리소스가 부족해서 스케줄링할 수 없는 파드를 발견하면 추가 노드를 자동으로 공급한다.

또한 오랜 시간 동안 사용률이 낮으면 노드를 줄인다.

<br>

***클라우드 인프라스트럭처에 추가 노드 요청***

새 파드가 생성된 후 스케줄러가 기존 노드에 스케줄링할 수 없는 경우, 새로운 노드가 공급된다.

클러스터 오토스케일러는 이런 파드를 찾고 클라우드 제공자에 추가 노드를 시작하도록 요청한다.

그러나 이를 수행하기 전에 새로운 노드가 파드를 수용할 수 있는지 확인한다.

클라우드 제공자는 동일한 크기의 노드들을 그룹으로 묶고 

클러스터 오토스케일러는 사용 가능한 노드 그룹을 검사해 최소한 하나의 노드 유형이 스케줄링되지 않은 파드를 수용할 수 있는지 확인한다.

<img src="https://user-images.githubusercontent.com/37579681/127740319-6756b647-8127-4732-946c-9c8f8b6b996e.jpeg">

<br>

***노드 종료***

클러스터 오토스케일러는 노드 리소스가 충분히 활용되고 있지 않을 때 노드 수를 줄여야 한다.

오토스케일러는 모든 노드에 요청된 CPU와 메모리를 모니터링해 이를 수행한다.

특정 노드에서 실행 중인 모든 파드의 CPU와 메모리 요청이 50% 미만이면 해당 노드는 필요하지 않은 것으로 간주한다.

물론 이것이 노드를 중단하는 데 사용하는 유일한 결정 요인은 아니다.

오토스케일러는 해당 노드에서만 실행 중인 시스템 파드가 있는지 검사하고 만약 시스템 파드가 노드에서 실행 중이라면 노드는 종료될 수 없다.

종료할 노드로 선택되면, 해당 노드는 먼저 스케줄링할 수 없다는 표시를 하고 노드에서 실행 중인 모든 파드를 제거한다.

---

<br>

### 클러스터 오토스케일러 활성화

다음 클라우드 제공자에서 사용할 수 있다.

- 구글 쿠버네티스 엔진
- 구글 컴퓨트 엔진
- 아마존 웹 서비스
- 마이크로소프트 애저

GKE 위에서 동작하고 있다면 다음 명령으로 활성화할 수 있다.

```bash
$ gcloud container clusters update kubia --enable-autoscaling --min-nodes=3 --max-nodes=5
```

<br>

---

<br>

### 클러스터 스케일 다운 동안에 서비스 중단 제한

노드가 예기치 않게 실패할 경우 파드가 사용 불가 상태가 되는 것을 막을 수 있는 방법이 없다.

하지만 노드 종료가 클러스터 오토스케일러나 시스템 관리자로 인해 이뤄지는 상황이라면,

추가 기능을 통해 해당 노드에서 실행되는 파드가 제공하는 서비스를 중단되지 않도록 할 수 있다.

특정 서비스에서는 최소 개수의 파드가 항상 실행돼야 한다.

쿠버네티스는 스케일 다운 등의 작업을 수행할 경우에도 유지돼야 하는 최소 파드 개수를 지정하는 방법을 제공한다.

PodDisruptionBudget 리소스는 오직 파드 레이블 셀렉터와 항상 사용 가능해야 하는 파드의 최소 개수 혹은 파드의 최대 개수를 정의할 수 있다.

```bash
# PodDisruptionBudget 리소스를 생성하자.
$ kubectl create pdb kubia-pdb --selector=app=kubia --min-available=3
```
리소스가 존재하는 동안 클러스터 오토스케일러와 kubectl drain 명령 모두 이를 준수해 app=kubia 레이블을 가진 파드가 정의해 둔 수 이하로 줄어들지 않는다.
